{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d733e1a-fff5-4739-b702-cc4af0a69d41",
   "metadata": {},
   "source": [
    "# How to build a simple Chatbot with stored memory using LangChain\n",
    "* Simple Chatbot LLM App.\n",
    "    * Will be able to have a conversation.\n",
    "    * Will remember previous interactions: will have memory.\n",
    "    * Will be able to store memory in a json file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077c88f7",
   "metadata": {},
   "source": [
    "A chatbot app is a software application designed to simulate conversation with human users. It uses artificial intelligence (AI) to understand what someone is saying and to respond with appropriate answers. These apps can be used for various purposes like customer support, providing information, or entertainment. Essentially, it's like texting with a program that can answer questions and help with tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0399355-dece-4701-9bf4-4c204fe74929",
   "metadata": {},
   "source": [
    "## Concepts included\n",
    "* Chat Model vs. LLM Model:\n",
    "    *  Chat Model is based around messages.\n",
    "    *  LLM Model is based around raw text.\n",
    "* Chat History: allows Chat Model to remember previous interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48386f20-c929-48a9-8720-0953fcd67dd0",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65ee060-21f2-4e01-b283-1fd656dac1e9",
   "metadata": {},
   "source": [
    "#### After you download the code from the github repository in your computer\n",
    "In terminal:\n",
    "* cd project_name\n",
    "* pyenv local 3.11.4\n",
    "* poetry install\n",
    "* poetry shell\n",
    "\n",
    "#### To open the notebook with Jupyter Notebooks\n",
    "In terminal:\n",
    "* jupyter lab\n",
    "\n",
    "Go to the folder of notebooks and open the right notebook.\n",
    "\n",
    "#### To see the code in Virtual Studio Code or your editor of choice.\n",
    "* open Virtual Studio Code or your editor of choice.\n",
    "* open the project-folder\n",
    "* open the 001-simple-chatbot.py file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43366d64-13e4-4b4e-b0ff-3113ff803fab",
   "metadata": {},
   "source": [
    "## Create your .env file\n",
    "* In the github repo we have included a file named .env.example\n",
    "* Rename that file to .env file and here is where you will add your confidential api keys. Remember to include:\n",
    "* OPENAI_API_KEY=your_openai_api_key\n",
    "* LANGCHAIN_TRACING_V2=true\n",
    "* LANGCHAIN_ENDPOINT=https://api.smith.langchain.com\n",
    "* LANGCHAIN_API_KEY=your_langchain_api_key\n",
    "* LANGCHAIN_PROJECT=your_project_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a63ff6-99ff-4629-b965-547d12a99ba6",
   "metadata": {},
   "source": [
    "We will call our LangSmith project **001-simple-chatbot**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7584e1f0-5e9e-4e45-850c-c606234b6ee2",
   "metadata": {},
   "source": [
    "## Trick to avoid the nasty deprecation warnings from LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b4224a-d719-46fd-b261-dd913b17ec86",
   "metadata": {},
   "source": [
    "In this exercise we will use the LangChain legacy chain LLMChain. It works well, but LangChain displays a nasty deprecation warning. To avoid it, we will enter the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eddbcf93-0b58-4506-af83-2fa2203c711c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from langchain._api import LangChainDeprecationWarning\n",
    "\n",
    "warnings.simplefilter(\"ignore\", category=LangChainDeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c0a44b-bbb4-4918-bd21-a62ee40f6d3f",
   "metadata": {},
   "source": [
    "## Connect with the .env file located in the same directory of this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e28f89-755a-455f-8f4e-70ccbb89c93e",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8626f160-fcd3-41ca-a5ab-3e98f11595a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "992ec4a9-aa01-4e44-aeb9-b9a1f3aa9e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c01d18b-f9f0-427b-a9dc-3d1885160578",
   "metadata": {},
   "source": [
    "#### Install LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceed6d60-5cbd-43e4-9a69-ed71d82a2a9b",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed746499-d1b8-41e5-b131-270cf5fa229b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2af3ef-c2c7-445f-92bd-a29c68abce25",
   "metadata": {},
   "source": [
    "## Connect with an LLM and start a conversation with it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659bdc4c-484d-4ec0-89b6-5f1e979610ce",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fa7337f-3d60-4ede-bdf8-aa7a5cffec43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce3551e-95ca-41a1-8810-89c495bf93ab",
   "metadata": {},
   "source": [
    "* For this project, we will use OpenAI's gpt-3.5-turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9afcbc7d-a816-41e3-925f-850883f5770d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chatbot = ChatOpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a1d409-7f2f-40a4-90c5-ad77dad3edce",
   "metadata": {},
   "source": [
    "* Human Message: the user input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5dc0613-fb6d-4c82-a614-9e7307714303",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "messagesToTheChatbot = [\n",
    "    HumanMessage(content=\"My favorite color is blue.\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479b36ec-341a-47bc-af32-30cfb939810d",
   "metadata": {},
   "source": [
    "#### Call the ChatModel (the LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db815e32-8e60-46b3-8cce-fbf40e378397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Blue is a calming and peaceful color that represents tranquility and serenity. It is often associated with the sky and the ocean, evoking feelings of freedom and openness. Blue is also known to symbolize trust, loyalty, and wisdom. Overall, blue is a versatile and timeless color that is loved by many.', response_metadata={'token_usage': {'completion_tokens': 63, 'prompt_tokens': 13, 'total_tokens': 76}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-c04030ec-cc97-4525-bcb6-617d9b705b64-0', usage_metadata={'input_tokens': 13, 'output_tokens': 63, 'total_tokens': 76})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot.invoke(messagesToTheChatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9913fc8c-254f-410d-aa8f-35eb0898855e",
   "metadata": {},
   "source": [
    "#### Track the operation in LangSmith\n",
    "* [Open LangSmith here](smith.langchain.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e62b67b-9798-4705-8b8a-dbfdf8c93ed8",
   "metadata": {},
   "source": [
    "## Check if the Chatbot remembers your favorite color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0ead4ee-bda3-4c52-9bdb-7bf234733055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm sorry, I do not have access to that information.\", response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 13, 'total_tokens': 26}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-a31d0a71-a438-4cf2-aae1-8b992b0581a7-0', usage_metadata={'input_tokens': 13, 'output_tokens': 13, 'total_tokens': 26})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot.invoke([\n",
    "    HumanMessage(content=\"What is my favorite color?\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faec947e-b9b7-43e3-ac67-60027e049f3c",
   "metadata": {},
   "source": [
    "* As you can see, our Chatbot cannot remember our previous interaction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df0143e-8bc8-45ad-ac6f-05aaf659c683",
   "metadata": {},
   "source": [
    "## Let's add memory to our Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6062df1-33ce-436e-b5b2-cea78ae7b860",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23533a37-6060-4d32-9b0c-36a9ea57a634",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "735752cc-ecb5-4942-9ed0-b3213f5768c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import LLMChain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import HumanMessagePromptTemplate\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.memory import FileChatMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "542bbf66-bc77-4488-8487-b55cdb8bc8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(\n",
    "    chat_memory=FileChatMessageHistory(\"messages.json\"),\n",
    "    memory_key=\"messages\",\n",
    "    return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27e8431b-5290-4f7f-9566-a90deb060bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate(\n",
    "    input_variables=[\"content\", \"messages\"],\n",
    "    messages=[\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{content}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72392539-0f20-456b-b32d-d367b48245f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juliocolomer/.pyenv/versions/3.11.4/envs/venv053024-p2/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "chain = LLMChain(\n",
    "    llm=chatbot,\n",
    "    prompt=prompt,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57e40af4-1539-497d-afbf-ed38fed90838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'hello!',\n",
       " 'messages': [],\n",
       " 'text': 'Hello! How can I assist you today?'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"hello!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b79cc08-49dd-4746-ab68-9d8ec992abb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'my name is Julio',\n",
       " 'messages': [HumanMessage(content='hello!'),\n",
       "  AIMessage(content='Hello! How can I assist you today?')],\n",
       " 'text': 'Nice to meet you, Julio! How can I help you today?'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"my name is Julio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96e69c4f-b5ed-4c68-9a2a-67a19867f8bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'what is my name?',\n",
       " 'messages': [HumanMessage(content='hello!'),\n",
       "  AIMessage(content='Hello! How can I assist you today?'),\n",
       "  HumanMessage(content='my name is Julio'),\n",
       "  AIMessage(content='Nice to meet you, Julio! How can I help you today?')],\n",
       " 'text': 'Your name is Julio.'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"what is my name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44245124-ef39-4269-a099-21c9c31c08bb",
   "metadata": {},
   "source": [
    "* Check the file messages.json in the root directory.\n",
    "* This is just a simple example, in the real world you probably will not save your memory in a json file. \n",
    "* And remember: the context window is limited and it affects to the cost of using chatGPT API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a9faf6-2772-4ef5-8241-d1e00c761ca4",
   "metadata": {},
   "source": [
    "## How to execute the code from Visual Studio Code\n",
    "* In Visual Studio Code, see the file 001-simple-chatbot.py\n",
    "* In terminal, make sure you are in the directory of the file and run:\n",
    "    * python 001-simple-chatbot.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44ba3a6-ff9c-49c5-b5a0-23f2ff7b367c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
